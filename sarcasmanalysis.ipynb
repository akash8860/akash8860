{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8688052,"sourceType":"datasetVersion","datasetId":5209188},{"sourceId":8688109,"sourceType":"datasetVersion","datasetId":5209235}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport re\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report\nfrom textblob import TextBlob","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-14T05:44:45.602942Z","iopub.execute_input":"2024-06-14T05:44:45.603458Z","iopub.status.idle":"2024-06-14T05:44:45.610659Z","shell.execute_reply.started":"2024-06-14T05:44:45.603403Z","shell.execute_reply":"2024-06-14T05:44:45.609390Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"pandas (pd): A powerful data manipulation and analysis library for Python. It provides data structures like DataFrame and Series for handling tabular data.\n\nnumpy (np): A fundamental package for scientific computing in Python. It provides support for arrays, matrices, and many mathematical functions.\n\nre: The regular expression library in Python. It provides functions to search, match, and manipulate strings using regular expressions.\n\nsklearn.model_selection.train_test_split: A function from Scikit-learn (a machine learning library) used to split arrays or matrices into random train and test subsets.\n\nsklearn.feature_extraction.text.TfidfVectorizer: A class from Scikit-learn used to convert a collection of raw documents to a matrix of TF-IDF features.\n\nsklearn.ensemble.RandomForestClassifier: A class from Scikit-learn used to implement a random forest classifier, an ensemble learning method for classification.\n\nsklearn.linear_model.LogisticRegression: A class from Scikit-learn used to implement logistic regression, a statistical method for binary classification.\n\nsklearn.metrics.classification_report: A function from Scikit-learn used to generate a text report showing the main classification metrics.\n\ntextblob.TextBlob: A class from TextBlob, a library for processing textual data. It provides a simple API for common natural language processing (NLP) tasks, such as part-of-speech tagging, noun phrase extraction, sentiment analysis, classification, translation, and more","metadata":{}},{"cell_type":"code","source":"# Preprocess the data\ndef preprocess_text(text):\n    text = re.sub(r'\\W', ' ', text)  # Remove non-word characters\n    text = text.lower()  # Convert text to lowercase\n    return text.strip()\n# Check the sentimental polarity\ndef get_sentiment_polarity(text):\n    analysis = TextBlob(text)\n    polarity = analysis.sentiment.polarity\n    return polarity","metadata":{"execution":{"iopub.status.busy":"2024-06-14T05:44:45.613586Z","iopub.execute_input":"2024-06-14T05:44:45.614088Z","iopub.status.idle":"2024-06-14T05:44:45.622054Z","shell.execute_reply.started":"2024-06-14T05:44:45.614047Z","shell.execute_reply":"2024-06-14T05:44:45.620773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load dataset 1 (for sentiment analysis)\ndataset1_path = '/kaggle/input/dataset/Dataset1.csv'\ndataset1 = pd.read_csv(dataset1_path)\ndataset1['text'] = dataset1['text'].apply(preprocess_text)\n\n# Load dataset 2 (for sarcasm detection)\ndataset2_path = '/kaggle/input/dataset/Dataset2.json'\ndataset2 = pd.read_json(dataset2_path)\ndataset2['headline'] = dataset2['headline'].apply(preprocess_text)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-14T05:44:45.623849Z","iopub.execute_input":"2024-06-14T05:44:45.624453Z","iopub.status.idle":"2024-06-14T05:44:45.887282Z","shell.execute_reply.started":"2024-06-14T05:44:45.624420Z","shell.execute_reply":"2024-06-14T05:44:45.886126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a TF-IDF Vectorizer object with a max of 5000 features and English stop words\nvectorizer = TfidfVectorizer(max_features=5000, stop_words='english')\n\n# Transform the 'headline' column of dataset2 into a TF-IDF matrix\nX_sarcasm = vectorizer.fit_transform(dataset2['headline']).toarray()\n\n# Extract the target variable 'is_sarcastic'\ny_sarcasm = dataset2['is_sarcastic']\n\n# Split the data into training and testing sets with a test size of 20% and a random state of 42\nX_sarcasm_train, X_sarcasm_test, y_sarcasm_train, y_sarcasm_test = train_test_split(\n    X_sarcasm, y_sarcasm, test_size=0.2, random_state=42)\n\n# Create a Random Forest Classifier object with 100 trees and a random state of 42\nsarcasm_model = RandomForestClassifier(n_estimators=100, random_state=42)\n\n# Fit the Random Forest model to the training data\nsarcasm_model.fit(X_sarcasm_train, y_sarcasm_train)","metadata":{"execution":{"iopub.status.busy":"2024-06-14T05:44:45.888943Z","iopub.execute_input":"2024-06-14T05:44:45.889355Z","iopub.status.idle":"2024-06-14T05:53:02.648855Z","shell.execute_reply.started":"2024-06-14T05:44:45.889316Z","shell.execute_reply":"2024-06-14T05:53:02.647732Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_sentiment = vectorizer.transform(dataset1['text']).toarray()\ny_sentiment = dataset1['sentiment'].map({'negative': 0, 'neutral': 1, 'positive': 2})\n\nX_sentiment_train, X_sentiment_test, y_sentiment_train, y_sentiment_test = train_test_split(\n    X_sentiment, y_sentiment, test_size=0.2, random_state=42)\n\nsentiment_model = LogisticRegression()\nsentiment_model.fit(X_sentiment_train, y_sentiment_train)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-14T05:53:02.651874Z","iopub.execute_input":"2024-06-14T05:53:02.652348Z","iopub.status.idle":"2024-06-14T05:53:07.739951Z","shell.execute_reply.started":"2024-06-14T05:53:02.652306Z","shell.execute_reply":"2024-06-14T05:53:07.738672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict_sentiment(text):\n    preprocessed_text = preprocess_text(text)\n    vectorized_text = vectorizer.transform([preprocessed_text]).toarray()\n\n    # Predict sarcasm\n    is_sarcastic = sarcasm_model.predict(vectorized_text)[0]\n\n    # Predict sentiment\n    predicted_sentiment = sentiment_model.predict(vectorized_text)[0]\n\n    # Adjust sentiment if sarcasm is detected\n    if is_sarcastic:\n        if predicted_sentiment == 0:\n            predicted_sentiment = 2  # Negative to Positive\n        elif predicted_sentiment == 2:\n            predicted_sentiment = 0  # Positive to Negative\n\n    # Map sentiment to labels\n    sentiment_labels = {0: 'negative', 1: 'neutral', 2: 'positive'}\n    final_sentiment = sentiment_labels[predicted_sentiment]\n\n    return final_sentiment","metadata":{"execution":{"iopub.status.busy":"2024-06-14T05:53:07.742330Z","iopub.execute_input":"2024-06-14T05:53:07.744103Z","iopub.status.idle":"2024-06-14T05:53:07.758302Z","shell.execute_reply.started":"2024-06-14T05:53:07.744054Z","shell.execute_reply":"2024-06-14T05:53:07.756499Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Example sentence\nexample_sentence = \"So happy with the service, it's been 2 days of power cut and this amazing company is not even replying to my complaint.\"\n\n# Predict sentiment\npredicted_sentiment = predict_sentiment(example_sentence)\n\n# Print results\nprint(f\"Sentence: {example_sentence}\")\nprint(f\"Predicted Sentiment: {predicted_sentiment}\")","metadata":{"execution":{"iopub.status.busy":"2024-06-14T05:53:07.760592Z","iopub.execute_input":"2024-06-14T05:53:07.762016Z","iopub.status.idle":"2024-06-14T05:53:07.796231Z","shell.execute_reply.started":"2024-06-14T05:53:07.761971Z","shell.execute_reply":"2024-06-14T05:53:07.794929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define preprocess_text function\ndef preprocess_text(text):\n    text = re.sub(r'\\W', ' ', text)  # Remove non-word characters\n    text = text.lower()  # Convert text to lowercase\n    return text.strip()\n\n# Load dataset 3\ndataset3_path = '/kaggle/input/new-cleaned/New_cleaned.xlsx'\ndataset3 = pd.read_excel(dataset3_path)\n\n# Preprocess text in dataset 3\ndataset3['text'] = dataset3['text'].astype(str).apply(preprocess_text)\n\n# Verify the updated dataset\nhead_rows = dataset3.head()  # Get first few rows to verify changes\nprint(head_rows)  # Print first few rows to verify changes\n","metadata":{"execution":{"iopub.status.busy":"2024-06-14T05:53:52.069308Z","iopub.execute_input":"2024-06-14T05:53:52.069704Z","iopub.status.idle":"2024-06-14T05:53:52.407235Z","shell.execute_reply.started":"2024-06-14T05:53:52.069671Z","shell.execute_reply":"2024-06-14T05:53:52.406142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Initialize an empty list to store predicted sentiments\npredicted_sentiments = []\n\n# Iterate over each text in dataset 3 and predict sentiment\nfor text in dataset3['text']:\n    predicted_sentiment = predict_sentiment(text)\n    predicted_sentiments.append(predicted_sentiment)\n\n# Add predicted sentiments to dataset 3\ndataset3['predicted_sentiment'] = predicted_sentiments","metadata":{"execution":{"iopub.status.busy":"2024-06-14T05:53:58.168755Z","iopub.execute_input":"2024-06-14T05:53:58.169327Z","iopub.status.idle":"2024-06-14T05:53:59.651119Z","shell.execute_reply.started":"2024-06-14T05:53:58.169290Z","shell.execute_reply":"2024-06-14T05:53:59.649865Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Compare predicted sentiments with actual sentiments if available in dataset 3\nif 'actual_sentiment' in dataset3.columns:\n    accuracy = (dataset3['predicted_sentiment'] == dataset3['actual_sentiment']).mean()\n    print(f\"Accuracy on dataset 3: {accuracy:.2f}\")\n\n# Set a default writable output path in Kaggle environment\ndefault_output_path = '/kaggle/working/New_cleaned1.xlsx'\n\n# Save the results to the default output path\ndataset3.to_excel(default_output_path, index=False)\nprint(f\"Results saved to {default_output_path}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-06-14T05:58:14.047356Z","iopub.execute_input":"2024-06-14T05:58:14.047721Z","iopub.status.idle":"2024-06-14T05:58:14.076604Z","shell.execute_reply.started":"2024-06-14T05:58:14.047694Z","shell.execute_reply":"2024-06-14T05:58:14.075504Z"},"trusted":true},"execution_count":null,"outputs":[]}]}