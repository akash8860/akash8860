{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/aki887/deep-sarcasm-analysis?scriptVersionId=213096470\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","execution_count":1,"id":"7680ca1e","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-12-14T22:03:25.886048Z","iopub.status.busy":"2024-12-14T22:03:25.885688Z","iopub.status.idle":"2024-12-14T22:03:28.924004Z","shell.execute_reply":"2024-12-14T22:03:28.922869Z"},"papermill":{"duration":3.048738,"end_time":"2024-12-14T22:03:28.927333","exception":false,"start_time":"2024-12-14T22:03:25.878595","status":"completed"},"tags":[]},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import re\n","from sklearn.model_selection import train_test_split\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import classification_report\n","from textblob import TextBlob"]},{"cell_type":"markdown","id":"6713b5e8","metadata":{"papermill":{"duration":0.003609,"end_time":"2024-12-14T22:03:28.936109","exception":false,"start_time":"2024-12-14T22:03:28.9325","status":"completed"},"tags":[]},"source":["pandas (pd): A powerful data manipulation and analysis library for Python. It provides data structures like DataFrame and Series for handling tabular data.\n","\n","numpy (np): A fundamental package for scientific computing in Python. It provides support for arrays, matrices, and many mathematical functions.\n","\n","re: The regular expression library in Python. It provides functions to search, match, and manipulate strings using regular expressions.\n","\n","sklearn.model_selection.train_test_split: A function from Scikit-learn (a machine learning library) used to split arrays or matrices into random train and test subsets.\n","\n","sklearn.feature_extraction.text.TfidfVectorizer: A class from Scikit-learn used to convert a collection of raw documents to a matrix of TF-IDF features.\n","\n","sklearn.ensemble.RandomForestClassifier: A class from Scikit-learn used to implement a random forest classifier, an ensemble learning method for classification.\n","\n","sklearn.linear_model.LogisticRegression: A class from Scikit-learn used to implement logistic regression, a statistical method for binary classification.\n","\n","sklearn.metrics.classification_report: A function from Scikit-learn used to generate a text report showing the main classification metrics.\n","\n","textblob.TextBlob: A class from TextBlob, a library for processing textual data. It provides a simple API for common natural language processing (NLP) tasks, such as part-of-speech tagging, noun phrase extraction, sentiment analysis, classification, translation, and more"]},{"cell_type":"code","execution_count":2,"id":"f29c5f10","metadata":{"execution":{"iopub.execute_input":"2024-12-14T22:03:28.944948Z","iopub.status.busy":"2024-12-14T22:03:28.944454Z","iopub.status.idle":"2024-12-14T22:03:28.950367Z","shell.execute_reply":"2024-12-14T22:03:28.949211Z"},"papermill":{"duration":0.012658,"end_time":"2024-12-14T22:03:28.952478","exception":false,"start_time":"2024-12-14T22:03:28.93982","status":"completed"},"tags":[]},"outputs":[],"source":["# Preprocess the data\n","def preprocess_text(text):\n","    text = re.sub(r'\\W', ' ', text)  # Remove non-word characters\n","    text = text.lower()  # Convert text to lowercase\n","    return text.strip()\n","# Check the sentimental polarity\n","def get_sentiment_polarity(text):\n","    analysis = TextBlob(text)\n","    polarity = analysis.sentiment.polarity\n","    return polarity"]},{"cell_type":"markdown","id":"dbde4aac","metadata":{"papermill":{"duration":0.003395,"end_time":"2024-12-14T22:03:28.95961","exception":false,"start_time":"2024-12-14T22:03:28.956215","status":"completed"},"tags":[]},"source":["\n","Explanation of Code Actions in Points:\n","preprocess_text function:\n","1. Removes non-word characters:\n","\n","Uses re.sub(r'\\W', ' ', text) to replace all non-word characters (e.g., symbols, punctuation) in the text with a space.\n","Ensures that only alphanumeric characters and spaces remain in the text.\n","\n","2. Converts text to lowercase:\n","\n","Uses text.lower() to standardize the text by converting all characters to lowercase.\n","Helps ensure case insensitivity during text analysis.\n","\n","3. Strips leading and trailing spaces:\n","\n","Uses text.strip() to remove unnecessary spaces at the beginning and end of the text, ensuring a cleaner input.\n","\n","get_sentiment_polarity function:\n","\n","1. Analyzes the sentiment of the text:\n","\n","Leverages the TextBlob library to perform a sentiment analysis on the input text. TextBlob uses lexicon-based methods to determine the sentiment.\n","\n","2. Calculates sentiment polarity:\n","\n","Extracts the sentiment.polarity attribute, which is a value between -1 and 1:\n","Negative polarity (-1 to 0): Indicates negative sentiment.\n","Zero polarity (0): Indicates a neutral sentiment.\n","Positive polarity (0 to 1): Indicates positive sentiment.\n","\n","3. Returns the polarity score:\n","\n","Provides a numerical representation of the sentiment to allow further categorization or analysis."]},{"cell_type":"code","execution_count":3,"id":"8a5f808e","metadata":{"execution":{"iopub.execute_input":"2024-12-14T22:03:28.968629Z","iopub.status.busy":"2024-12-14T22:03:28.967764Z","iopub.status.idle":"2024-12-14T22:03:29.333918Z","shell.execute_reply":"2024-12-14T22:03:29.332919Z"},"papermill":{"duration":0.373281,"end_time":"2024-12-14T22:03:29.336374","exception":false,"start_time":"2024-12-14T22:03:28.963093","status":"completed"},"tags":[]},"outputs":[],"source":["# Load dataset 1 (for sentiment analysis)\n","dataset1_path = '/kaggle/input/dataset/Dataset1.csv'\n","dataset1 = pd.read_csv(dataset1_path)\n","dataset1['text'] = dataset1['text'].apply(preprocess_text)\n","\n","# Load dataset 2 (for sarcasm detection)\n","dataset2_path = '/kaggle/input/dataset/Dataset2.json'\n","dataset2 = pd.read_json(dataset2_path)\n","dataset2['headline'] = dataset2['headline'].apply(preprocess_text)\n"]},{"cell_type":"markdown","id":"53533478","metadata":{"papermill":{"duration":0.003323,"end_time":"2024-12-14T22:03:29.343304","exception":false,"start_time":"2024-12-14T22:03:29.339981","status":"completed"},"tags":[]},"source":["Explanation of Code Actions in Points:\n","\n","Loading Dataset 1 (for Sentiment Analysis):\n","\n","1. Defines the path to the CSV dataset:\n","\n","The path /kaggle/input/dataset/Dataset1.csv specifies the location of the first dataset, which is assumed to be in CSV format.\n","\n","2. Loads the CSV file into a DataFrame:\n","\n","Uses pd.read_csv(dataset1_path) to load the dataset into a Pandas DataFrame for structured data manipulation.\n","\n","3. Applies text preprocessing to the text column:\n","\n","Uses dataset1['text'].apply(preprocess_text) to preprocess the text column in the DataFrame.\n","Removes non-word characters, converts text to lowercase, and strips extra spaces.\n","Prepares the text data for sentiment analysis by ensuring consistency and cleanliness.\n","\n","Loading Dataset 2 (for Sarcasm Detection):\n","\n","1. Defines the path to the JSON dataset:\n","\n","The path /kaggle/input/dataset/Dataset2.json specifies the location of the second dataset, which is assumed to be in JSON format.\n","\n","2. Loads the JSON file into a DataFrame:\n","\n","Uses pd.read_json(dataset2_path) to load the dataset into a Pandas DataFrame, converting JSON structured data into tabular form.\n","\n","3. Applies text preprocessing to the headline column:\n","\n","Uses dataset2['headline'].apply(preprocess_text) to preprocess the headline column.\n","Cleans the text data for sarcasm detection by standardizing and removing irrelevant characters.\n","\n","Outcome of These Steps:\n","\n","Dataset 1 is preprocessed and ready for sentiment analysis tasks.\n","Dataset 2 is preprocessed and prepared for sarcasm detection tasks.\n","\n"]},{"cell_type":"code","execution_count":4,"id":"64995dcf","metadata":{"execution":{"iopub.execute_input":"2024-12-14T22:03:29.351865Z","iopub.status.busy":"2024-12-14T22:03:29.351218Z","iopub.status.idle":"2024-12-14T22:11:16.676969Z","shell.execute_reply":"2024-12-14T22:11:16.675807Z"},"papermill":{"duration":467.336215,"end_time":"2024-12-14T22:11:16.682878","exception":false,"start_time":"2024-12-14T22:03:29.346663","status":"completed"},"tags":[]},"outputs":[{"data":{"text/html":["<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div></div></div>"],"text/plain":["RandomForestClassifier(random_state=42)"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["# Create a TF-IDF Vectorizer object with a max of 5000 features and English stop words\n","vectorizer = TfidfVectorizer(max_features=5000, stop_words='english')\n","\n","# Transform the 'headline' column of dataset2 into a TF-IDF matrix\n","X_sarcasm = vectorizer.fit_transform(dataset2['headline']).toarray()\n","\n","# Extract the target variable 'is_sarcastic'\n","y_sarcasm = dataset2['is_sarcastic']\n","\n","# Split the data into training and testing sets with a test size of 20% and a random state of 42\n","X_sarcasm_train, X_sarcasm_test, y_sarcasm_train, y_sarcasm_test = train_test_split(\n","    X_sarcasm, y_sarcasm, test_size=0.2, random_state=42)\n","\n","# Create a Random Forest Classifier object with 100 trees and a random state of 42\n","sarcasm_model = RandomForestClassifier(n_estimators=100, random_state=42)\n","\n","# Fit the Random Forest model to the training data\n","sarcasm_model.fit(X_sarcasm_train, y_sarcasm_train)"]},{"cell_type":"markdown","id":"78976812","metadata":{"papermill":{"duration":0.003423,"end_time":"2024-12-14T22:11:16.689985","exception":false,"start_time":"2024-12-14T22:11:16.686562","status":"completed"},"tags":[]},"source":["Create a TF-IDF Vectorizer:\n","\n","Converts text data into a numerical matrix with a maximum of 5000 features.\n","Removes common English stop words (e.g., \"the,\" \"and\") to focus on important terms.\n","\n","Transform the text data:\n","\n","Converts the headline column from dataset2 into a TF-IDF matrix (X_sarcasm), making it suitable for machine learning models.\n","\n","Extract the target variable:\n","\n","y_sarcasm holds the sarcasm labels (e.g., 1 for sarcastic, 0 for non-sarcastic).\n","\n","Split the data:\n","\n","Splits the features (X_sarcasm) and target (y_sarcasm) into training (80%) and testing (20%) sets for model training and evaluation.\n","\n","Create the Random Forest Classifier:\n","\n","Initializes a Random Forest model with 100 decision trees for sarcasm classification.\n","\n","Train the model:\n","\n","Fits the Random Forest model on the training data (X_sarcasm_train and y_sarcasm_train).\n","\n","The model learns to classify sarcasm based on the patterns in the data."]},{"cell_type":"code","execution_count":5,"id":"0e5cbe90","metadata":{"execution":{"iopub.execute_input":"2024-12-14T22:11:16.699161Z","iopub.status.busy":"2024-12-14T22:11:16.698434Z","iopub.status.idle":"2024-12-14T22:11:22.007407Z","shell.execute_reply":"2024-12-14T22:11:22.004959Z"},"papermill":{"duration":5.321394,"end_time":"2024-12-14T22:11:22.015016","exception":false,"start_time":"2024-12-14T22:11:16.693622","status":"completed"},"tags":[]},"outputs":[{"data":{"text/html":["<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"],"text/plain":["LogisticRegression()"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["X_sentiment = vectorizer.transform(dataset1['text']).toarray()\n","y_sentiment = dataset1['sentiment'].map({'negative': 0, 'neutral': 1, 'positive': 2})\n","\n","X_sentiment_train, X_sentiment_test, y_sentiment_train, y_sentiment_test = train_test_split(\n","    X_sentiment, y_sentiment, test_size=0.2, random_state=42)\n","\n","sentiment_model = LogisticRegression()\n","sentiment_model.fit(X_sentiment_train, y_sentiment_train)\n"]},{"cell_type":"markdown","id":"9943e778","metadata":{"papermill":{"duration":0.030495,"end_time":"2024-12-14T22:11:22.07899","exception":false,"start_time":"2024-12-14T22:11:22.048495","status":"completed"},"tags":[]},"source":["1. Transform sentiment text data:\n","\n","Converts the text column in dataset1 into a numerical matrix (X_sentiment) using the same TF-IDF vectorizer.\n","\n","2. Map sentiment labels to numbers:\n","\n","Converts the sentiment labels:\n","'negative' → 0\n","'neutral' → 1\n","'positive' → 2\n","Stores these numeric values in y_sentiment.\n","\n","3. Split the data:\n","\n","Divides the features (X_sentiment) and labels (y_sentiment) into training (80%) and testing (20%) sets for training and evaluation.\n","\n","4. Create the Logistic Regression model:\n","\n","Initializes a Logistic Regression model to classify text into sentiment categories.\n","\n","5. Train the model:\n","\n","Fits the model on the training data (X_sentiment_train and y_sentiment_train) to learn how to predict sentiment."]},{"cell_type":"code","execution_count":6,"id":"d3c5642f","metadata":{"execution":{"iopub.execute_input":"2024-12-14T22:11:22.114479Z","iopub.status.busy":"2024-12-14T22:11:22.114111Z","iopub.status.idle":"2024-12-14T22:11:22.120132Z","shell.execute_reply":"2024-12-14T22:11:22.119111Z"},"papermill":{"duration":0.014034,"end_time":"2024-12-14T22:11:22.12225","exception":false,"start_time":"2024-12-14T22:11:22.108216","status":"completed"},"tags":[]},"outputs":[],"source":["def predict_sentiment(text):\n","    preprocessed_text = preprocess_text(text)\n","    vectorized_text = vectorizer.transform([preprocessed_text]).toarray()\n","\n","    # Predict sarcasm\n","    is_sarcastic = sarcasm_model.predict(vectorized_text)[0]\n","\n","    # Predict sentiment\n","    predicted_sentiment = sentiment_model.predict(vectorized_text)[0]\n","\n","    # Adjust sentiment if sarcasm is detected\n","    if is_sarcastic:\n","        if predicted_sentiment == 0:\n","            predicted_sentiment = 2  # Negative to Positive\n","        elif predicted_sentiment == 2:\n","            predicted_sentiment = 0  # Positive to Negative\n","\n","    # Map sentiment to labels\n","    sentiment_labels = {0: 'negative', 1: 'neutral', 2: 'positive'}\n","    final_sentiment = sentiment_labels[predicted_sentiment]\n","\n","    return final_sentiment"]},{"cell_type":"code","execution_count":7,"id":"bc5865f9","metadata":{"execution":{"iopub.execute_input":"2024-12-14T22:11:22.131883Z","iopub.status.busy":"2024-12-14T22:11:22.131207Z","iopub.status.idle":"2024-12-14T22:11:22.145581Z","shell.execute_reply":"2024-12-14T22:11:22.144418Z"},"papermill":{"duration":0.02125,"end_time":"2024-12-14T22:11:22.147574","exception":false,"start_time":"2024-12-14T22:11:22.126324","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Sentence: So happy with the service, it's been 2 days of power cut and this amazing company is not even replying to my complaint.\n","Predicted Sentiment: negative\n"]}],"source":["# Example sentence\n","example_sentence = \"So happy with the service, it's been 2 days of power cut and this amazing company is not even replying to my complaint.\"\n","\n","# Predict sentiment\n","predicted_sentiment = predict_sentiment(example_sentence)\n","\n","# Print results\n","print(f\"Sentence: {example_sentence}\")\n","print(f\"Predicted Sentiment: {predicted_sentiment}\")"]},{"cell_type":"code","execution_count":8,"id":"a775fea5","metadata":{"execution":{"iopub.execute_input":"2024-12-14T22:11:22.157551Z","iopub.status.busy":"2024-12-14T22:11:22.157198Z","iopub.status.idle":"2024-12-14T22:11:22.485185Z","shell.execute_reply":"2024-12-14T22:11:22.484152Z"},"papermill":{"duration":0.335689,"end_time":"2024-12-14T22:11:22.487262","exception":false,"start_time":"2024-12-14T22:11:22.151573","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["                                                text\n","0  1   when people ask me stupid questions  it is...\n","1  2   i m not saying i hate you  what i m saying...\n","2         3   silence is golden  duct tape is silver\n","3  4   i am busy right now  can i ignore you some...\n","4          5   find your patience before i lose mine\n"]}],"source":["# Define preprocess_text function\n","def preprocess_text(text):\n","    text = re.sub(r'\\W', ' ', text)  # Remove non-word characters\n","    text = text.lower()  # Convert text to lowercase\n","    return text.strip()\n","\n","# Load dataset 3\n","dataset3_path = '/kaggle/input/new-cleaned/New_cleaned.xlsx'\n","dataset3 = pd.read_excel(dataset3_path)\n","\n","# Preprocess text in dataset 3\n","dataset3['text'] = dataset3['text'].astype(str).apply(preprocess_text)\n","\n","# Verify the updated dataset\n","head_rows = dataset3.head()  # Get first few rows to verify changes\n","print(head_rows)  # Print first few rows to verify changes\n"]},{"cell_type":"code","execution_count":9,"id":"e776cde4","metadata":{"execution":{"iopub.execute_input":"2024-12-14T22:11:22.497048Z","iopub.status.busy":"2024-12-14T22:11:22.496214Z","iopub.status.idle":"2024-12-14T22:11:23.734972Z","shell.execute_reply":"2024-12-14T22:11:23.733737Z"},"papermill":{"duration":1.246093,"end_time":"2024-12-14T22:11:23.737337","exception":false,"start_time":"2024-12-14T22:11:22.491244","status":"completed"},"tags":[]},"outputs":[],"source":["# Initialize an empty list to store predicted sentiments\n","predicted_sentiments = []\n","\n","# Iterate over each text in dataset 3 and predict sentiment\n","for text in dataset3['text']:\n","    predicted_sentiment = predict_sentiment(text)\n","    predicted_sentiments.append(predicted_sentiment)\n","\n","# Add predicted sentiments to dataset 3\n","dataset3['predicted_sentiment'] = predicted_sentiments"]},{"cell_type":"code","execution_count":10,"id":"d315b781","metadata":{"execution":{"iopub.execute_input":"2024-12-14T22:11:23.747166Z","iopub.status.busy":"2024-12-14T22:11:23.746833Z","iopub.status.idle":"2024-12-14T22:11:23.780926Z","shell.execute_reply":"2024-12-14T22:11:23.779755Z"},"papermill":{"duration":0.041424,"end_time":"2024-12-14T22:11:23.783004","exception":false,"start_time":"2024-12-14T22:11:23.74158","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Results saved to /kaggle/working/New_cleaned1.xlsx\n"]}],"source":["# Compare predicted sentiments with actual sentiments if available in dataset 3\n","if 'actual_sentiment' in dataset3.columns:\n","    accuracy = (dataset3['predicted_sentiment'] == dataset3['actual_sentiment']).mean()\n","    print(f\"Accuracy on dataset 3: {accuracy:.2f}\")\n","\n","# Set a default writable output path in Kaggle environment\n","default_output_path = '/kaggle/working/New_cleaned1.xlsx'\n","\n","# Save the results to the default output path\n","dataset3.to_excel(default_output_path, index=False)\n","print(f\"Results saved to {default_output_path}\")\n"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":5209188,"sourceId":8688052,"sourceType":"datasetVersion"},{"datasetId":5209235,"sourceId":8688109,"sourceType":"datasetVersion"}],"dockerImageVersionId":30732,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"papermill":{"default_parameters":{},"duration":481.725476,"end_time":"2024-12-14T22:11:24.508804","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-12-14T22:03:22.783328","version":"2.5.0"}},"nbformat":4,"nbformat_minor":5}